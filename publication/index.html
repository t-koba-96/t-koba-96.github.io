<!DOCTYPE html>
<!-- This site was created with Wowchemy. https://www.wowchemy.com -->
<!-- Last Published: May 28, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Wowchemy 5.7.0 for Hugo" />
  

  
  












  
  










  







  
  

  
  
  

  
  

  
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css" integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      
        
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.b6d003f494885717a4e7a7dae0d96b7b.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  


























  
  
  






  <meta name="author" content="Takuya Kobayashi" />





  

<meta name="description" content="Blog Page." />



<link rel="alternate" hreflang="en-us" href="https://t-koba-96.github.io/publication/" />
<link rel="canonical" href="https://t-koba-96.github.io/publication/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_huf124860b709ba3b7e308c7ad48690209_1175483_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_huf124860b709ba3b7e308c7ad48690209_1175483_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#707070" />










  
  






<meta property="twitter:card" content="summary" />
<meta property="twitter:image" content="https://t-koba-96.github.io/media/icon_huf124860b709ba3b7e308c7ad48690209_1175483_512x512_fill_lanczos_center_3.png" />
<meta property="og:site_name" content="Bianca Blog" />
<meta property="og:url" content="https://t-koba-96.github.io/publication/" />
<meta property="og:title" content="論文ゆる要約 | Bianca Blog" />
<meta property="og:description" content="Blog Page." /><meta property="og:image" content="https://t-koba-96.github.io/media/icon_huf124860b709ba3b7e308c7ad48690209_1175483_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta property="og:updated_time" content="2022-08-01T00:00:00&#43;00:00" />
  










  
  
  

  
  
    <link rel="alternate" href="/publication/index.xml" type="application/rss+xml" title="Bianca Blog" />
  

  


  
  <title>論文ゆる要約 | Bianca Blog</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="3a079e7dad19be978a318345a7749d34" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.fe8634e7d00f14d07fb33caf14cc8e55.js"></script>

  




  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">Bianca Blog</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">Bianca Blog</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-center" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link  active" href="/publication"><span>PaperSummaries</span></a>
          </li>

          
          

          

          
          
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/blog"><span>BlogPosts</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link " href="/published"><span>Works</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        

        
        
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    













<div class="article-header">
  
  
    <img src="/media/brooklin.png" width="910" height="512" class="article-banner" alt="">
  

  
</div>




  

  
  
  
    
  
<div class="universal-wrapper pt-3">
  <h1>論文ゆる要約</h1>

  
  <p class="page-subtitle"><hr></p>
  

  
</div>



<div class="universal-wrapper">
  <div class="row">
    <div class="col-lg-12">

      

      
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      
        
        
      

      <div class="form-row mb-4">
        <div class="col-auto">
          <input type="search" class="filter-search form-control form-control-sm" placeholder="Search..." autocapitalize="off"
          autocomplete="off" autocorrect="off" role="textbox" spellcheck="false">
        </div>
        <div class="col-auto">
          <select class="pub-filters pubtype-select form-control form-control-sm" data-filter-group="pubtype">
            <option value="*">Type</option>
            
            
            <option value=".pubtype-0">
              CVPR
            </option>
            
            <option value=".pubtype-1">
              ICLR
            </option>
            
            <option value=".pubtype-2">
              NeurIPS
            </option>
            
            <option value=".pubtype-3">
              ICCV
            </option>
            
            <option value=".pubtype-5">
              ECCV
            </option>
            
            <option value=".pubtype-6">
              AAAI
            </option>
            
            <option value=".pubtype-7">
              Others
            </option>
            
          </select>
        </div>
        <div class="col-auto">
          <select class="pub-filters form-control form-control-sm" data-filter-group="year">
            <option value="*">Date</option>
            
            
            
            <option value=".year-2022">
              2022
            </option>
            
            <option value=".year-2021">
              2021
            </option>
            
            <option value=".year-2020">
              2020
            </option>
            
            <option value=".year-2019">
              2019
            </option>
            
            <option value=".year-2018">
              2018
            </option>
            
            <option value=".year-2017">
              2017
            </option>
            
            <option value=".year-2016">
              2016
            </option>
            
            <option value=".year-2014">
              2014
            </option>
            
            
          </select>
        </div>
      </div>

      <div id="container-publications">
        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-5 year-2022">
          









  




<div class="card">
  
  
  <a href="/publication/unified-fully/"  class="card-image hover-overlay">
    <img src="/publication/unified-fully/featured_hu6494ce94c54193947d14e6b7e4ed462a_41689_550x0_resize_q75_h2_lanczos.webp" height="163" width="550"
         alt="Unified Fully and Timestamp Supervised Temporal Action Segmentation via Sequence to Sequence Translation" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/unified-fully/" >Unified Fully and Timestamp Supervised Temporal Action Segmentation via Sequence to Sequence Translation</a></h4>

    
    <div class="article-style">
      <p>Few-shot Learning においてTransormerを用いた局所の表現学習方法を提案。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2209.00638.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/boschresearch/UVAST" target="_blank" rel="noopener">
  Code
</a>














    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-0 year-2021">
          









  




<div class="card">
  
  
  <a href="/publication/temporal-relational-crosstransformers/"  class="card-image hover-overlay">
    <img src="/publication/temporal-relational-crosstransformers/featured_hudea331519166e284ef0db00f0b511031_103974_550x0_resize_q75_h2_lanczos.webp" height="438" width="550"
         alt="Temporal-Relational CrossTransformers for Few-Shot Action Recognition" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/temporal-relational-crosstransformers/" >Temporal-Relational CrossTransformers for Few-Shot Action Recognition</a></h4>

    
    <div class="article-style">
      <p>CrossTransformerを応用したFew-Shotの行動認識手法の提案。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Perrett_Temporal-Relational_CrossTransformers_for_Few-Shot_Action_Recognition_CVPR_2021_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/tobyperrett/trx" target="_blank" rel="noopener">
  Code
</a>














    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-0 year-2021">
          









  




<div class="card">
  
  
  <a href="/publication/elaborative_rehearsal_for_zero-shot_action_recognition/"  class="card-image hover-overlay">
    <img src="/publication/elaborative_rehearsal_for_zero-shot_action_recognition/featured_hu12d0ecdce71df59d5cb2f8ba392ba3b6_141448_550x0_resize_q75_h2_lanczos_3.webp" height="328" width="550"
         alt="Elaborative Rehearsal for Zero-shot Action Recognition" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/elaborative_rehearsal_for_zero-shot_action_recognition/" >Elaborative Rehearsal for Zero-shot Action Recognition</a></h4>

    
    <div class="article-style">
      <p>シーングラフ生成のタスクで既存のVisualGenomeデータセットにおける実験考察をもとに，新たにLSTMを用いた手法を提案。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Chen_Elaborative_Rehearsal_for_Zero-Shot_Action_Recognition_ICCV_2021_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>

















    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2020">
          









  




<div class="card">
  
  
  <a href="/publication/crosstransformers/"  class="card-image hover-overlay">
    <img src="/publication/crosstransformers/featured_hu27874d1ae8519ed5975d2fe2f47d43d5_57203_550x0_resize_q75_h2_lanczos.webp" height="233" width="550"
         alt="CrossTransformers: spatially-aware few-shot transfer" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/crosstransformers/" >CrossTransformers: spatially-aware few-shot transfer</a></h4>

    
    <div class="article-style">
      <p>Few-shot Learning においてTransormerを用いた局所の表現学習方法を提案。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/2007.11498.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/skrish13/CrossTransformers-PyTorch" target="_blank" rel="noopener">
  Code
</a>


  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/google-research/meta-dataset" target="_blank" rel="noopener">
  Dataset
</a>









  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://papertalk.org/papertalks/9911" target="_blank" rel="noopener">
  Video
</a>





    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-0 year-2020">
          









  




<div class="card">
  
  
  <a href="/publication/action-genome/"  class="card-image hover-overlay">
    <img src="/publication/action-genome/featured_hu71bfa5c80b04307b85fa082fee6e4e56_66191_550x0_resize_q75_h2_lanczos_3.webp" height="358" width="550"
         alt="Action Genome: Actions as Composition of Spatio-temporal Scene Graphs" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/action-genome/" >Action Genome: Actions as Composition of Spatio-temporal Scene Graphs</a></h4>

    
    <div class="article-style">
      <p>Visual Genomeの動画版のデータセット。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1912.06992.pdf" target="_blank" rel="noopener">
  PDF
</a>

















    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-0 year-2019">
          









  




<div class="card">
  
  
  <a href="/publication/videobert/"  class="card-image hover-overlay">
    <img src="/publication/videobert/featured_huc12533a8ff74fb12ea657065b6a9be58_1607434_550x0_resize_q75_h2_lanczos_3.webp" height="203" width="550"
         alt="VideoBERT: A Joint Model for Video and Language Representation Learning" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/videobert/" >VideoBERT: A Joint Model for Video and Language Representation Learning</a></h4>

    
    <div class="article-style">
      <p>多くのモデルでVisionとLanguageでネットワークをそれぞれ用意して同時に学習させていた部分を，Bertを応用することでマルチモーダルに事前学習させる方法。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1904.01766.pdf" target="_blank" rel="noopener">
  PDF
</a>

















    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-3 year-2019">
          









  




<div class="card">
  
  
  <a href="/publication/video-representation-learning-by-dense-predictive-coding/"  class="card-image hover-overlay">
    <img src="/publication/video-representation-learning-by-dense-predictive-coding/featured_hub3d93721d74319119f5eea1bb634284c_76087_550x0_resize_q75_h2_lanczos_3.webp" height="225" width="550"
         alt="Video Representation Learning by Dense Predictive Coding" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/video-representation-learning-by-dense-predictive-coding/" >Video Representation Learning by Dense Predictive Coding</a></h4>

    
    <div class="article-style">
      <p>Predictive Codingで用いた手法を動画にも適用した論文。動画の次の潜在表現を回帰で予測させてあげて，相互情報量の最大化を目指す。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1909.04656.pdf" target="_blank" rel="noopener">
  PDF
</a>

















    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-0 year-2019">
          









  




<div class="card">
  
  
  <a href="/publication/temporal-cycle-consistency/"  class="card-image hover-overlay">
    <img src="/publication/temporal-cycle-consistency/featured_hu6ce7c09b5ad60bc6040a2f5463a8738c_76943_550x0_resize_q75_h2_lanczos_3.webp" height="326" width="550"
         alt="Temporal Cycle-Consistency Learning" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/temporal-cycle-consistency/" >Temporal Cycle-Consistency Learning</a></h4>

    
    <div class="article-style">
      <p>異なる動画においても，同じ動作の場合特徴空間上で近くなるように学習させることで，似た動作の動画同士を同期できるようなマッチングを実現。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1904.07846.pdf" target="_blank" rel="noopener">
  PDF
</a>

















    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-0 year-2019">
          









  




<div class="card">
  
  
  <a href="/publication/ms-tcn/"  class="card-image hover-overlay">
    <img src="/publication/ms-tcn/featured_hufa2c606aae58c31cc3f9dabca8e433fc_137002_550x0_resize_q75_h2_lanczos.webp" height="542" width="550"
         alt="MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/ms-tcn/" >MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation</a></h4>

    
    <div class="article-style">
      <p>行動認識のタスクにおいて,Temporal Convolutional Networksを複数重ねるMulti-TCNの提案。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1903.01945.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/yabufarha/ms-tcn" target="_blank" rel="noopener">
  Code
</a>








  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://xpaperchallenge.org/cv/survey/cvpr2019_summaries/422/" target="_blank" rel="noopener">
  Slides
</a>







    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-0 year-2019">
          









  




<div class="card">
  
  
  <a href="/publication/long-term-feature-banks/"  class="card-image hover-overlay">
    <img src="/publication/long-term-feature-banks/featured_hud08bb8ba71c2b6f168ec29d4501f232d_83240_550x0_resize_q75_h2_lanczos_3.webp" height="316" width="550"
         alt="Long-Term Feature Banks for Detailed Video Understanding" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/long-term-feature-banks/" >Long-Term Feature Banks for Detailed Video Understanding</a></h4>

    
    <div class="article-style">
      <p>３DCNNでは4秒近くにおける時系列情報しか捉えられない。そこでよりLongTermな情報と組み合わせて考えることでVideoRecognitionの精度が上がりましたよという論文。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1812.05038.pdf" target="_blank" rel="noopener">
  PDF
</a>

















    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-0 year-2019">
          









  




<div class="card">
  
  
  <a href="/publication/graphical-contrastive-loss/"  class="card-image hover-overlay">
    <img src="/publication/graphical-contrastive-loss/featured_hu5b50b3d3cef88e3b21f965cc1db46992_411924_550x0_resize_q75_h2_lanczos_3.webp" height="256" width="550"
         alt="Graphical Contrastive Losses for Scene Graph Parsing" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/graphical-contrastive-loss/" >Graphical Contrastive Losses for Scene Graph Parsing</a></h4>

    
    <div class="article-style">
      <p>シーングラフの生成において従来モデルの課題点を指摘した上で，それを改善するための新たなロスを提案し，SoTAを達成。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Graphical_Contrastive_Losses_for_Scene_Graph_Parsing_CVPR_2019_paper.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/NVIDIA/ContrastiveLosses4VRD" target="_blank" rel="noopener">
  Code
</a>














    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-0 year-2019">
          









  




<div class="card">
  
  
  <a href="/publication/completeness-modeling/"  class="card-image hover-overlay">
    <img src="/publication/completeness-modeling/featured_hu2a4f0ccd2ab3db97dbdc453bf95dbc20_205478_550x0_resize_q75_h2_lanczos_3.webp" height="251" width="550"
         alt="Completeness Modeling and Context Separation for Weakly Supervised Temporal Action Localization" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/completeness-modeling/" >Completeness Modeling and Context Separation for Weakly Supervised Temporal Action Localization</a></h4>

    
    <div class="article-style">
      <p>Predictive Codingで用いた手法を動画にも適用した論文。動画の次の潜在表現を回帰で予測させてあげて，相互情報量の最大化を目指す。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1909.04656.pdf" target="_blank" rel="noopener">
  PDF
</a>

















    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-3 year-2019">
          









  




<div class="card">
  
  
  <a href="/publication/bmn/"  class="card-image hover-overlay">
    <img src="/publication/bmn/featured_hu709846f091761e6ab1066e47664e6db4_241921_550x0_resize_q75_h2_lanczos_3.webp" height="401" width="550"
         alt="BMN: Boundary-Matching Network for Temporal Action Proposal Generation" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/bmn/" >BMN: Boundary-Matching Network for Temporal Action Proposal Generation</a></h4>

    
    <div class="article-style">
      <p>Temporal action proposalのタスク。従来のような始点終点予測とは別に，Proposalの始点と長さを表すヒートマップを作成する。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1907.09702.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/JJBOY/BMN-Boundary-Matching-Network" target="_blank" rel="noopener">
  Code
</a>














    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-7 year-2019">
          









  




<div class="card">
  
  
  <a href="/publication/bert/"  class="card-image hover-overlay">
    <img src="/publication/bert/featured_huf9afe52928347e42cf5d84515dd0402c_64927_550x0_resize_q75_h2_lanczos_3.webp" height="219" width="550"
         alt="BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/bert/" >BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></h4>

    
    <div class="article-style">
      <p>言語の事前学習によって，自然言語分野の複数のタスクにおいてSoTAを達成。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/google-research/bert" target="_blank" rel="noopener">
  Code
</a>














    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-0 year-2018">
          









  




<div class="card">
  
  
  <a href="/publication/weakly-iterative-soft-boundary-assignment/"  class="card-image hover-overlay">
    <img src="/publication/weakly-iterative-soft-boundary-assignment/featured_hu876356bb6e998613cad45e77de77fed0_132490_550x0_resize_q75_h2_lanczos.webp" height="353" width="550"
         alt="Weakly-Supervised Action Segmentation with Iterative Soft Boundary Assignment" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/weakly-iterative-soft-boundary-assignment/" >Weakly-Supervised Action Segmentation with Iterative Soft Boundary Assignment</a></h4>

    
    <div class="article-style">
      <p>Action Segmentation のタスクにおいてWeakly-supervisedな手法. 学習用の動画デートセットの正解として，動画内の行動ラベルの順番のみ与える（各フレームにおける正解ラベルはなし）.</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1803.10699.pdf" target="_blank" rel="noopener">
  PDF
</a>

















    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-7 year-2018">
          









  




<div class="card">
  
  
  <a href="/publication/time-contrastive-networks/"  class="card-image hover-overlay">
    <img src="/publication/time-contrastive-networks/featured_hu08d337835ee91ed227bd1e5d2091afce_1101505_550x0_resize_q75_h2_lanczos_3.webp" height="458" width="550"
         alt="Time-Contrastive Networks: Self-Supervised Learning from Video" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/time-contrastive-networks/" >Time-Contrastive Networks: Self-Supervised Learning from Video</a></h4>

    
    <div class="article-style">
      <p>Action recognitionにおけるSelf-supervisedな事前学習方法の提案。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1704.06888.pdf" target="_blank" rel="noopener">
  PDF
</a>

















    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-6 year-2018">
          









  




<div class="card">
  
  
  <a href="/publication/spatial-temporal-graph-convolutional-networks/"  class="card-image hover-overlay">
    <img src="/publication/spatial-temporal-graph-convolutional-networks/featured_hu17c9ed98c4a15a0d689a350b0fe6e434_65374_550x0_resize_q75_h2_lanczos_3.webp" height="116" width="550"
         alt="Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/spatial-temporal-graph-convolutional-networks/" >Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition</a></h4>

    
    <div class="article-style">
      <p>時空間方向のグラフ畳み込みを利用したSkeleton-basedな行動認識手法を提案。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1801.07455v2.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/yysijie/st-gcn" target="_blank" rel="noopener">
  Code
</a>














    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-7 year-2018">
          









  




<div class="card">
  
  
  <a href="/publication/representation-learning-with-contrastive-predictive-coding/"  class="card-image hover-overlay">
    <img src="/publication/representation-learning-with-contrastive-predictive-coding/featured_hub97073688491be623befcc21255359ce_42157_550x0_resize_q75_h2_lanczos_3.webp" height="268" width="550"
         alt="Representation Learning with Contrastive Predictive Coding" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/representation-learning-with-contrastive-predictive-coding/" >Representation Learning with Contrastive Predictive Coding</a></h4>

    
    <div class="article-style">
      <p>画像や音声における新しい表現学習の方法を提案。エンコーダーとGRUを組み合わせてGRUが次のエンコーダの出力を予測して,その相互情報量の最大化によって良い特徴表現を獲得する。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1807.03748.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/jefflai108/Contrastive-Predictive-Coding-PyTorch" target="_blank" rel="noopener">
  Code
</a>








  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.slideshare.net/slideshow/embed_code/key/oXPMOqFzCWe0Va" target="_blank" rel="noopener">
  Slides
</a>







    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-3 year-2018">
          









  




<div class="card">
  
  
  <a href="/publication/neuralnetwork-viterbi/"  class="card-image hover-overlay">
    <img src="/publication/neuralnetwork-viterbi/featured_huc87b6e4c71e350091e5d07b979aad7b9_54610_550x0_resize_q75_h2_lanczos_3.webp" height="362" width="550"
         alt="NeuralNetwork-Viterbi: A Framework for Weakly Supervised Video Learning" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/neuralnetwork-viterbi/" >NeuralNetwork-Viterbi: A Framework for Weakly Supervised Video Learning</a></h4>

    
    <div class="article-style">
      <p>クラスラベルの遷移順のみのWeaklyなラベルを用いたAction Segmentation. Viterbi algorism を用いた方法を提案。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://alexanderrichard.github.io/publications/pdf/richard_nn_viterbi.pdf" target="_blank" rel="noopener">
  PDF
</a>

















    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-0 year-2018">
          









  




<div class="card">
  
  
  <a href="/publication/neural-motifs/"  class="card-image hover-overlay">
    <img src="/publication/neural-motifs/featured_hucf8aaf7ad280f60c809ccd28968411df_478767_550x0_resize_q75_h2_lanczos_3.webp" height="416" width="550"
         alt="Neural Motifs: Scene Graph Parsing with Global Context" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/neural-motifs/" >Neural Motifs: Scene Graph Parsing with Global Context</a></h4>

    
    <div class="article-style">
      <p>シーングラフ生成のタスクで既存のVisualGenomeデータセットにおける実験考察をもとに，新たにLSTMを用いた手法を提案。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1711.06640.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/rowanz/neural-motifs" target="_blank" rel="noopener">
  Code
</a>














    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-5 year-2018">
          









  




<div class="card">
  
  
  <a href="/publication/graph-rcnn/"  class="card-image hover-overlay">
    <img src="/publication/graph-rcnn/featured_hua266015fb9adb45cae3498270e59518e_225671_550x0_resize_q75_h2_lanczos_3.webp" height="300" width="550"
         alt="Graph R-CNN for Scene Graph Generation" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/graph-rcnn/" >Graph R-CNN for Scene Graph Generation</a></h4>

    
    <div class="article-style">
      <p>GraphConvolutionを用いてSceneGraphの生成をより正確に行うための手法。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1808.00191.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/jwyang/graph-rcnn.pytorch" target="_blank" rel="noopener">
  Code
</a>














    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-0 year-2017">
          









  




<div class="card">
  
  
  <a href="/publication/temporal-convolutional-networks/"  class="card-image hover-overlay">
    <img src="/publication/temporal-convolutional-networks/featured_hu54d2620fcc983787fb5a2940ef29e96b_96795_550x0_resize_q75_h2_lanczos.webp" height="451" width="550"
         alt="Temporal Convolutional Networks for Action Segmentation and Detection" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/temporal-convolutional-networks/" >Temporal Convolutional Networks for Action Segmentation and Detection</a></h4>

    
    <div class="article-style">
      <p>詳細な行動認識のタスクにおいて、長期的な時系列情報を考慮するように畳み込みを行って認識を行うネットワークであるTemporal Convolutional Networkの提案.</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1611.05267.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/locuslab/TCN" target="_blank" rel="noopener">
  Code
</a>














    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2017">
          









  




<div class="card">
  
  
  <a href="/publication/attention-is-all-you-need/"  class="card-image hover-overlay">
    <img src="/publication/attention-is-all-you-need/featured_hu861de42d3dbc14c14257ab9741c34836_52282_550x0_resize_q75_h2_lanczos_3.webp" height="696" width="550"
         alt="Attention is all you need" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/attention-is-all-you-need/" >Attention is all you need</a></h4>

    
    <div class="article-style">
      <p>機械翻訳用のネットワークの提案。従来LSTMやGRUや畳み込みを主に用いていた自然言語の処理だが，アテンションのみを用いて単語間の関連性を考慮するような手法。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1903.01945.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/yabufarha/ms-tcn" target="_blank" rel="noopener">
  Code
</a>








  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">
  Slides
</a>







    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-7 year-2016">
          









  




<div class="card">
  
  
  <a href="/publication/visual-genome/"  class="card-image hover-overlay">
    <img src="/publication/visual-genome/featured_huff0cea17884f488cc021a07c959d73a8_254160_550x0_resize_q75_h2_lanczos_3.webp" height="319" width="550"
         alt="Visual Genome : Connecting Language and Vision Using Crowdsourced Dense Image Annotations" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/visual-genome/" >Visual Genome : Connecting Language and Vision Using Crowdsourced Dense Image Annotations</a></h4>

    
    <div class="article-style">
      <p>画像をもとにしたシーングラフやそれに関連したVQA等のラベルがついたVisual Genome データセットを作成。</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1602.07332.pdf" target="_blank" rel="noopener">
  PDF
</a>





  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="http://visualgenome.org/" target="_blank" rel="noopener">
  Dataset
</a>













    </div>
    
  </div>
</div>

        </div>

        

        
          
        

        <div class="grid-sizer col-lg-12 isotope-item pubtype-2 year-2014">
          









  




<div class="card">
  
  
  <a href="/publication/two-stream-convolutional-networks/"  class="card-image hover-overlay">
    <img src="/publication/two-stream-convolutional-networks/featured_hu94070c74519dc667695e26f58781afa5_139070_550x0_resize_q75_h2_lanczos_3.webp" height="219" width="550"
         alt="Two-Stream Convolutional Networks for Action Recognition in Videos" class="img-responsive" loading="lazy">
  </a>
  
  <div class="card-text">
    <h4><a href="/publication/two-stream-convolutional-networks/" >Two-Stream Convolutional Networks for Action Recognition in Videos</a></h4>

    
    <div class="article-style">
      <p>空間情報（静止画）と時間情報（ フレーム間の動き）をそれぞれ畳み込んだ結果を統合することによる行動認識の手法を提案.</p>
    </div>
    

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://arxiv.org/pdf/1406.2199.pdf" target="_blank" rel="noopener">
  PDF
</a>




  
  
    
  
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://github.com/jeffreyhuang1/two-stream-action-recognition" target="_blank" rel="noopener">
  Code
</a>














    </div>
    
  </div>
</div>

        </div>

        
      </div>

    </div>
  </div>
</div>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Wowchemy</a> — the free, <a href="https://github.com/wowchemy/wowchemy-hugo-themes" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.46271ef31da3f018e9cd1b59300aa265.js"></script>




  
    <script src="https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js" integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js" integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin="anonymous"></script>
  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>

























<script id="page-data" type="application/json">{"use_headroom":true}</script>



  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>










<script src="/en/js/wowchemy.min.62ee204c51ab1af036605c7fd0a94a0b.js"></script>



  <script src="/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>




  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js" type="module"></script>


















</body>
</html>
